{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T23:40:42.374553Z",
     "start_time": "2025-10-18T23:40:42.371948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow.core.config.flags import config\n",
    "\n",
    "root_dir = str(Path.cwd().parent.parent.absolute())\n",
    "if not root_dir in sys.path:\n",
    "    sys.path.insert(0, root_dir)"
   ],
   "id": "3819a6da2f262f31",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T23:40:44.534032Z",
     "start_time": "2025-10-18T23:40:44.530431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "from config import Config\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "config = Config.to_dict()"
   ],
   "id": "fae5556e89853142",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('../data/raw/dataset_en.txt', 'r', encoding='utf-8') as f:\n",
    "    english = f.readlines()\n",
    "\n",
    "with open('../data/raw/dataset_vi.txt', 'r', encoding='utf-8') as f:\n",
    "    vietnamese = f.readlines()"
   ],
   "id": "c801687b29231a44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # ðŸ“Š Data Exploration - English-Vietnamese Translation Dataset\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Load Data\n",
    "\n",
    "# %%\n",
    "# Load datasets\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'english': [line.strip() for line in english],\n",
    "    'vietnamese': [line.strip() for line in vietnamese]\n",
    "})\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head(10)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Basic Statistics\n",
    "\n",
    "# %%\n",
    "# Sentence lengths\n",
    "df['en_length'] = df['english'].apply(lambda x: len(x.split()))\n",
    "df['vi_length'] = df['vietnamese'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(\"English sentences:\")\n",
    "print(df['en_length'].describe())\n",
    "print(\"\\nVietnamese sentences:\")\n",
    "print(df['vi_length'].describe())\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Length Distribution\n",
    "\n",
    "# %%\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# English\n",
    "axes[0].hist(df['en_length'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('English Sentence Length Distribution')\n",
    "axes[0].set_xlabel('Number of Words')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(df['en_length'].mean(), color='red', linestyle='--',\n",
    "                label=f'Mean: {df[\"en_length\"].mean():.1f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Vietnamese\n",
    "axes[1].hist(df['vi_length'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].set_title('Vietnamese Sentence Length Distribution')\n",
    "axes[1].set_xlabel('Number of Words')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].axvline(df['vi_length'].mean(), color='red', linestyle='--',\n",
    "                label=f'Mean: {df[\"vi_length\"].mean():.1f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Vocabulary Analysis\n",
    "\n",
    "# %%\n",
    "def count_vocab(texts):\n",
    "    word_freq = Counter()\n",
    "    for text in texts:\n",
    "        word_freq.update(text.lower().split())\n",
    "    return word_freq\n",
    "\n",
    "en_vocab = count_vocab(df['english'])\n",
    "vi_vocab = count_vocab(df['vietnamese'])\n",
    "\n",
    "print(f\"English vocabulary size: {len(en_vocab):,}\")\n",
    "print(f\"Vietnamese vocabulary size: {len(vi_vocab):,}\")\n",
    "\n",
    "print(\"\\nTop 20 English words:\")\n",
    "print(en_vocab.most_common(20))\n",
    "\n",
    "print(\"\\nTop 20 Vietnamese words:\")\n",
    "print(vi_vocab.most_common(20))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Rare Words Analysis\n",
    "\n",
    "# %%\n",
    "# Words appearing only once\n",
    "en_rare = [w for w, c in en_vocab.items() if c == 1]\n",
    "vi_rare = [w for w, c in vi_vocab.items() if c == 1]\n",
    "\n",
    "print(f\"English rare words (freq=1): {len(en_rare):,} ({len(en_rare)/len(en_vocab)*100:.1f}%)\")\n",
    "print(f\"Vietnamese rare words (freq=1): {len(vi_rare):,} ({len(vi_rare)/len(vi_vocab)*100:.1f}%)\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Length Filtering Impact\n",
    "\n",
    "# %%\n",
    "# Test different max lengths\n",
    "max_lengths = [20, 30, 40, 50, 60]\n",
    "\n",
    "for max_len in max_lengths:\n",
    "    filtered = df[(df['en_length'] <= max_len) & (df['vi_length'] <= max_len)]\n",
    "    kept_pct = len(filtered) / len(df) * 100\n",
    "    print(f\"Max length {max_len}: {len(filtered):,}/{len(df):,} pairs ({kept_pct:.1f}%)\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Sample Pairs\n",
    "\n",
    "# %%\n",
    "print(\"Random sample pairs:\\n\")\n",
    "for i in df.sample(5).index:\n",
    "    print(f\"EN: {df.loc[i, 'english']}\")\n",
    "    print(f\"VI: {df.loc[i, 'vietnamese']}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
