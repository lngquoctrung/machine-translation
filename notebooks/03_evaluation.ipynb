{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c031167e883dbe",
   "metadata": {},
   "source": [
    "# **Model Evaluation & Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc85e3b7ed4e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = str(Path.cwd().parent.absolute())\n",
    "if not root_dir in sys.path:\n",
    "    sys.path.insert(0, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3671c0a407a0680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 13:07:37.575504: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-22 13:07:37.634629: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-22 13:07:38.974964: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.evaluation.metrics import BLEUScore\n",
    "from src.evaluation.beam_search import BeamSearchDecoder\n",
    "from src.data.preprocessing import DataPreprocessor\n",
    "from src.utils import load_tokenizer\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0d2aeebe9aa03",
   "metadata": {},
   "source": [
    "## **1. Load Models & Tokenizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48801ef3800b1926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761113259.937701 1450830 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3470 MB memory:  -> device: 0, name: NVIDIA GeForce MX230, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded from .../artifacts/tokenizers/tokenizer_en.pkl\n",
      "Tokenizer loaded from .../artifacts/tokenizers/tokenizer_vi.pkl\n",
      "Models and tokenizers loaded\n"
     ]
    }
   ],
   "source": [
    "# Load BiLSTM model\n",
    "bilstm_model = tf.keras.models.load_model(\n",
    "    f\"{Config.ARTIFACT_PATH}/bilstm/final_bilstm_model.keras\",\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "# Load LSTM model\n",
    "lstm_model = tf.keras.models.load_model(\n",
    "    f\"{Config.ARTIFACT_PATH}/lstm/final_lstm_model.keras\",\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "# Load tokenizers\n",
    "tokenizer_en = load_tokenizer(f\"{Config.ARTIFACT_PATH}/tokenizers/tokenizer_en.pkl\")\n",
    "tokenizer_vi = load_tokenizer(f\"{Config.ARTIFACT_PATH}/tokenizers/tokenizer_vi.pkl\")\n",
    "\n",
    "print(\"Models and tokenizers loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3ff3cbfe69629d",
   "metadata": {},
   "source": [
    "## **2. Setup Decoders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20f1bd17fa2e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_decoder = BeamSearchDecoder(\n",
    "    bilstm_model, tokenizer_en, tokenizer_vi,\n",
    "    Config.MAX_LENGTH_SRC, Config.MAX_LENGTH_TRG\n",
    ")\n",
    "\n",
    "lstm_decoder = BeamSearchDecoder(\n",
    "    lstm_model, tokenizer_en, tokenizer_vi,\n",
    "    Config.MAX_LENGTH_SRC, Config.MAX_LENGTH_TRG\n",
    ")\n",
    "\n",
    "bleu_scorer = BLEUScore(weights=[0.25, 0.25, 0.25, 0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a5d882ee202c6",
   "metadata": {},
   "source": [
    "## **3. Test Translations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c12b4ced8098c882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRANSLATION TESTS\n",
      "================================================================================\n",
      "\n",
      "Input: Hello, how are you?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 13:07:42.992544: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM: <UNK> <UNK> bạn <UNK> như <UNK>\n",
      "LSTM: <UNK> <UNK> <UNK> bạn\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: I love machine learning.\n",
      "BiLSTM: tôi <UNK> <UNK> <UNK>\n",
      "LSTM: tôi <UNK> <UNK> <UNK>\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: The weather is beautiful today.\n",
      "BiLSTM: <UNK> <UNK> <UNK> <UNK>\n",
      "LSTM: <UNK> <UNK> <UNK> <UNK>\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: Can you help me with this problem?\n",
      "BiLSTM: bạn có_thể <UNK> tôi <UNK> <UNK> này không\n",
      "LSTM: bạn có_thể <UNK> tôi với <UNK> này không\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: Thank you for your time.\n",
      "BiLSTM: <UNK> bạn đã <UNK> <UNK> của <UNK>\n",
      "LSTM: <UNK> bạn <UNK> <UNK> của bạn\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"I love machine learning.\",\n",
    "    \"The weather is beautiful today.\",\n",
    "    \"Can you help me with this problem?\",\n",
    "    \"Thank you for your time.\"\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRANSLATION TESTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for text in test_sentences:\n",
    "    print(f\"\\nInput: {text}\")\n",
    "\n",
    "    # BiLSTM\n",
    "    bilstm_trans = bilstm_decoder.translate(text)\n",
    "    print(f\"BiLSTM: {bilstm_trans}\")\n",
    "\n",
    "    # LSTM\n",
    "    lstm_trans = lstm_decoder.translate(text)\n",
    "    print(f\"LSTM: {lstm_trans}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252cc31b7c287d61",
   "metadata": {},
   "source": [
    "## **4. BLEU Score Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92cbcf3e21d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "preprocessor = DataPreprocessor(\n",
    "    max_vocab_src=Config.MAX_VOCAB_SIZE_SRC,\n",
    "    max_vocab_trg=Config.MAX_VOCAB_SIZE_TRG\n",
    ")\n",
    "\n",
    "df = preprocessor.load_data(\n",
    "    src_path=f\"{Config.DATA_PATH}/raw/en.txt\",\n",
    "    trg_path=f\"{Config.DATA_PATH}/raw/vi.txt\",\n",
    "    max_length_src=Config.MAX_LENGTH_SRC,\n",
    "    max_length_trg=Config.MAX_LENGTH_TRG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feca962521f2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test set\n",
    "_, _, test_df = preprocessor.split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeadf0bd29f3a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set (sample 100 for speed)\n",
    "test_sample = test_df.sample(n=min(100, len(test_df)))\n",
    "\n",
    "bilstm_bleu_scores = []\n",
    "lstm_bleu_scores = []\n",
    "\n",
    "for idx, row in test_sample.iterrows():\n",
    "    en_text = row['src']\n",
    "    vi_ref = row['trg'].replace('START ', '').replace(' END', '')\n",
    "\n",
    "    # BiLSTM\n",
    "    bilstm_trans = bilstm_decoder.translate(en_text)\n",
    "    bilstm_bleu = bleu_scorer.compute(vi_ref, bilstm_trans)\n",
    "    bilstm_bleu_scores.append(bilstm_bleu)\n",
    "\n",
    "    # LSTM\n",
    "    lstm_trans = lstm_decoder.translate(en_text)\n",
    "    lstm_bleu = bleu_scorer.compute(vi_ref, lstm_trans)\n",
    "    lstm_bleu_scores.append(lstm_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a73db8bb3aef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BLEU SCORE EVALUATION (100 samples)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"BiLSTM - Average BLEU: {np.mean(bilstm_bleu_scores):.2f}\")\n",
    "print(f\"LSTM - Average BLEU: {np.mean(lstm_bleu_scores):.2f}\")\n",
    "print(f\"Improvement: {np.mean(bilstm_bleu_scores) - np.mean(lstm_bleu_scores):.2f} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c3fdd4e2208f1",
   "metadata": {},
   "source": [
    "## **5. Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.hist(bilstm_bleu_scores, bins=20, alpha=0.7, label='BiLSTM', edgecolor='black')\n",
    "ax.hist(lstm_bleu_scores, bins=20, alpha=0.7, label='LSTM', edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('BLEU Score')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('BLEU Score Distribution Comparison')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'{Config.ASSETS_PATH}/bleu_comparison.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c0b15fd15f6df",
   "metadata": {},
   "source": [
    "## **6. Summary Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce273161dde9d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL EVALUATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBiLSTM Model:\")\n",
    "print(f\"  - Average BLEU: {np.mean(bilstm_bleu_scores):.2f}\")\n",
    "print(f\"  - Min BLEU: {np.min(bilstm_bleu_scores):.2f}\")\n",
    "print(f\"  - Max BLEU: {np.max(bilstm_bleu_scores):.2f}\")\n",
    "print(f\"  - Parameters: {bilstm_model.count_params():,}\")\n",
    "\n",
    "print(f\"\\nLSTM Model:\")\n",
    "print(f\"  - Average BLEU: {np.mean(lstm_bleu_scores):.2f}\")\n",
    "print(f\"  - Min BLEU: {np.min(lstm_bleu_scores):.2f}\")\n",
    "print(f\"  - Max BLEU: {np.max(lstm_bleu_scores):.2f}\")\n",
    "print(f\"  - Parameters: {lstm_model.count_params():,}\")\n",
    "\n",
    "print(f\"\\nConclusion:\")\n",
    "print(f\"  BiLSTM performs {np.mean(bilstm_bleu_scores) - np.mean(lstm_bleu_scores):.2f} BLEU points better\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
