{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Model Evaluation & Testing**",
   "id": "d8c031167e883dbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = str(Path.cwd().parent.parent.absolute())\n",
    "if not root_dir in sys.path:\n",
    "    sys.path.insert(0, root_dir)"
   ],
   "id": "bdc85e3b7ed4e8ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.evaluation.metrics import BLEUScore\n",
    "from src.evaluation.beam_search import BeamSearchDecoder\n",
    "from src.data.preprocessing import DataPreprocessor\n",
    "from src.utils import load_tokenizer\n",
    "from config import Config\n",
    "\n",
    "config = Config.to_dict()"
   ],
   "id": "3671c0a407a0680c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **1. Load Models & Tokenizers**",
   "id": "d2a0d2aeebe9aa03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load BiLSTM model\n",
    "bilstm_model = tf.keras.models.load_model(\n",
    "    f\"{config[\"model_save_path\"]}/bilstm_model.h5\",\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "# Load LSTM model\n",
    "lstm_model = tf.keras.models.load_model(\n",
    "    f\"{config[\"model_save_path\"]}/lstm_model.h5\",\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "# Load tokenizers\n",
    "tokenizer_en = load_tokenizer(f\"{config['tokenizer_path']}/tokenizer_en.pkl\")\n",
    "tokenizer_vi = load_tokenizer(f\"{config['tokenizer_path']}/tokenizer_vi.pkl\")\n",
    "\n",
    "print(\"Models and tokenizers loaded\")"
   ],
   "id": "48801ef3800b1926"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **2. Setup Decoders**",
   "id": "ee3ff3cbfe69629d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bilstm_decoder = BeamSearchDecoder(\n",
    "    bilstm_model, tokenizer_en, tokenizer_vi,\n",
    "    config['max_length_src'], config['max_length_trg']\n",
    ")\n",
    "\n",
    "lstm_decoder = BeamSearchDecoder(\n",
    "    lstm_model, tokenizer_en, tokenizer_vi,\n",
    "    config['max_length_src'], config['max_length_trg']\n",
    ")\n",
    "\n",
    "bleu_scorer = BLEUScore()"
   ],
   "id": "a20f1bd17fa2e8dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **3. Test Translations**",
   "id": "851a5d882ee202c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_sentences = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"I love machine learning.\",\n",
    "    \"The weather is beautiful today.\",\n",
    "    \"Can you help me with this problem?\",\n",
    "    \"Thank you for your time.\"\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRANSLATION TESTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for text in test_sentences:\n",
    "    print(f\"\\nInput: {text}\")\n",
    "\n",
    "    # BiLSTM\n",
    "    bilstm_trans = bilstm_decoder.translate(text)\n",
    "    print(f\"BiLSTM: {bilstm_trans}\")\n",
    "\n",
    "    # LSTM\n",
    "    lstm_trans = lstm_decoder.translate(text)\n",
    "    print(f\"LSTM: {lstm_trans}\")\n",
    "    print(\"-\"*80)"
   ],
   "id": "c12b4ced8098c882"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **4. BLEU Score Evaluation**",
   "id": "252cc31b7c287d61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load test data\n",
    "preprocessor = DataPreprocessor(\n",
    "    max_vocab_src=config['max_vocab_size_src'],\n",
    "    max_vocab_trg=config['max_vocab_size_trg']\n",
    ")\n",
    "\n",
    "df = preprocessor.load_data(\n",
    "    src_path=f\"{config[\"data_path\"]}/raw/en.txt\",\n",
    "    trg_path=f\"{config[\"data_path\"]}/raw/vi.txt\",\n",
    "    max_length_src=config['max_length_src'],\n",
    "    max_length_trg=config['max_length_trg']\n",
    ")"
   ],
   "id": "b92cbcf3e21d6dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get test set\n",
    "_, _, test_df = preprocessor.split_data(df)"
   ],
   "id": "7feca962521f2620"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate on test set (sample 100 for speed)\n",
    "test_sample = test_df.sample(n=min(100, len(test_df)))\n",
    "\n",
    "bilstm_bleu_scores = []\n",
    "lstm_bleu_scores = []\n",
    "\n",
    "for idx, row in test_sample.iterrows():\n",
    "    en_text = row['english']\n",
    "    vi_ref = row['vietnamese'].replace('START ', '').replace(' END', '')\n",
    "\n",
    "    # BiLSTM\n",
    "    bilstm_trans = bilstm_decoder.translate(en_text)\n",
    "    bilstm_bleu = bleu_scorer.compute(vi_ref, bilstm_trans)\n",
    "    bilstm_bleu_scores.append(bilstm_bleu)\n",
    "\n",
    "    # LSTM\n",
    "    lstm_trans = lstm_decoder.translate(en_text)\n",
    "    lstm_bleu = bleu_scorer.compute(vi_ref, lstm_trans)\n",
    "    lstm_bleu_scores.append(lstm_bleu)"
   ],
   "id": "eeadf0bd29f3a28d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BLEU SCORE EVALUATION (100 samples)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"BiLSTM - Average BLEU: {np.mean(bilstm_bleu_scores):.2f}\")\n",
    "print(f\"LSTM - Average BLEU: {np.mean(lstm_bleu_scores):.2f}\")\n",
    "print(f\"Improvement: {np.mean(bilstm_bleu_scores) - np.mean(lstm_bleu_scores):.2f} points\")"
   ],
   "id": "f9a73db8bb3aef53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **5. Visualization**",
   "id": "ad2c3fdd4e2208f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.hist(bilstm_bleu_scores, bins=20, alpha=0.7, label='BiLSTM', edgecolor='black')\n",
    "ax.hist(lstm_bleu_scores, bins=20, alpha=0.7, label='LSTM', edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('BLEU Score')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('BLEU Score Distribution Comparison')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{config[\"assets_path\"]}/bleu_comparison.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **6. Summary Report**",
   "id": "348c0b15fd15f6df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL EVALUATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBiLSTM Model:\")\n",
    "print(f\"  - Average BLEU: {np.mean(bilstm_bleu_scores):.2f}\")\n",
    "print(f\"  - Min BLEU: {np.min(bilstm_bleu_scores):.2f}\")\n",
    "print(f\"  - Max BLEU: {np.max(bilstm_bleu_scores):.2f}\")\n",
    "print(f\"  - Parameters: {bilstm_model.count_params():,}\")\n",
    "\n",
    "print(f\"\\nLSTM Model:\")\n",
    "print(f\"  - Average BLEU: {np.mean(lstm_bleu_scores):.2f}\")\n",
    "print(f\"  - Min BLEU: {np.min(lstm_bleu_scores):.2f}\")\n",
    "print(f\"  - Max BLEU: {np.max(lstm_bleu_scores):.2f}\")\n",
    "print(f\"  - Parameters: {lstm_model.count_params():,}\")\n",
    "\n",
    "print(f\"\\nConclusion:\")\n",
    "print(f\"  BiLSTM performs {np.mean(bilstm_bleu_scores) - np.mean(lstm_bleu_scores):.2f} BLEU points better\")\n",
    "print(\"=\"*80)"
   ],
   "id": "ce273161dde9d1f4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
