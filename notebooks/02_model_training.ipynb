{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T04:25:19.734967Z",
     "iopub.status.busy": "2025-10-21T04:25:19.734736Z",
     "iopub.status.idle": "2025-10-21T04:25:25.928274Z",
     "shell.execute_reply": "2025-10-21T04:25:25.927572Z",
     "shell.execute_reply.started": "2025-10-21T04:25:19.734948Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T04:25:25.929465Z",
     "iopub.status.busy": "2025-10-21T04:25:25.929210Z",
     "iopub.status.idle": "2025-10-21T04:25:26.614441Z",
     "shell.execute_reply": "2025-10-21T04:25:26.613769Z",
     "shell.execute_reply.started": "2025-10-21T04:25:25.929430Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== Set up project ======\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Copy source code to working directory\n",
    "src_path = r\"/kaggle/input/machine-translation/\"\n",
    "dst_path = r\"/kaggle/working/machine-translation/\"\n",
    "\n",
    "shutil.copytree(src_path, dst_path, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root directory to PYTHON path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# === LOCAL ===\n",
    "# root_dir = str(Path.cwd().parent.parent.absolute())\n",
    "# if not root_dir in sys.path:\n",
    "#     sys.path.insert(0, root_dir)\n",
    "\n",
    "# === KAGGLE ===\n",
    "root_dir = \"/kaggle/working/machine-translation\"\n",
    "if not root_dir in sys.path:\n",
    "    sys.path.insert(0, root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Training - LSTM & BiLSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import Config\n",
    "from src.utils.gpu_utils import GPUMemoryManager\n",
    "from src.data.preprocessing import DataPreprocessor\n",
    "from src.models.bilstm_attention import BiLSTMAttentionModel\n",
    "from src.models.lstm_attention import LSTMAttentionModel\n",
    "from src.training.trainer import ModelTrainer\n",
    "from src.utils.helpers import save_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy outputs from previous version to working directory \n",
    "# (Used to continue training the model if the allowed session runs out)\n",
    "input_dirs = [\n",
    "    d for d in os.listdir('/kaggle/input/') if 'machine-translation-model-training' in d\n",
    "]\n",
    "\n",
    "if input_dirs:\n",
    "    input_dir = f\"/kaggle/input/{input_dirs[0]}/\"\n",
    "    work_dir = \"/kaggle/working/machine-translation/\"\n",
    "    \n",
    "    os.makedirs(input_dir, exist_ok=True)\n",
    "    shutil.copytree(\n",
    "        input_dir, \n",
    "        work_dir, \n",
    "        ignore=[\"src\"], \n",
    "        dirs_exist_ok=True\n",
    "    )\n",
    "    \n",
    "    print(\"Loaded outputs from previous version\")\n",
    "else:\n",
    "    print(\"No previous outputs found. Starting fresh.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. GPU Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:40:54.821626Z",
     "start_time": "2025-10-19T09:40:54.388049Z"
    },
    "execution": {
     "iopub.execute_input": "2025-10-21T04:25:39.561362Z",
     "iopub.status.busy": "2025-10-21T04:25:39.560867Z",
     "iopub.status.idle": "2025-10-21T04:25:40.348532Z",
     "shell.execute_reply": "2025-10-21T04:25:40.347890Z",
     "shell.execute_reply.started": "2025-10-21T04:25:39.561338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "GPUMemoryManager.clear_session()\n",
    "GPUMemoryManager.setup_gpu(\n",
    "    memory_limit_mb=Config.GPU_MEMORY_LIMIT,\n",
    "    allow_growth=Config.GPU_MEMORY_GROWTH\n",
    ")\n",
    "if Config.USE_MIXED_PRECISION:\n",
    "    GPUMemoryManager.enable_mixed_precision()\n",
    "    GPUMemoryManager.get_memory_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:41:10.849096Z",
     "start_time": "2025-10-19T09:41:10.844406Z"
    },
    "execution": {
     "iopub.execute_input": "2025-10-21T04:25:40.349428Z",
     "iopub.status.busy": "2025-10-21T04:25:40.349136Z",
     "iopub.status.idle": "2025-10-21T04:25:40.354497Z",
     "shell.execute_reply": "2025-10-21T04:25:40.353744Z",
     "shell.execute_reply.started": "2025-10-21T04:25:40.349408Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = Config.to_dict()\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"\\nMemory Estimate:\")\n",
    "for key, value in Config.estimate_memory().items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T10:22:48.978571Z",
     "start_time": "2025-10-19T10:22:48.408884Z"
    },
    "execution": {
     "iopub.execute_input": "2025-10-21T04:25:40.355465Z",
     "iopub.status.busy": "2025-10-21T04:25:40.355172Z",
     "iopub.status.idle": "2025-10-21T04:25:41.078045Z",
     "shell.execute_reply": "2025-10-21T04:25:41.077388Z",
     "shell.execute_reply.started": "2025-10-21T04:25:40.355448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer_path = f\"{Config.ARTIFACT_PATH}/tokenizers\"\n",
    "\n",
    "preprocessor = DataPreprocessor(\n",
    "    max_vocab_src=Config.MAX_VOCAB_SIZE_SRC,\n",
    "    max_vocab_trg=Config.MAX_LENGTH_TRG,\n",
    "    min_frequency=Config.MIN_WORD_FREQUENCY,\n",
    "    name_logger=\"data_preprocessing\",\n",
    "    filename_logger=f\"{Config.LOG_DIR}/data_preprocessing.log\"\n",
    ")\n",
    "\n",
    "# Load data\n",
    "df = preprocessor.load_data(\n",
    "    src_path=f\"{Config.DATA_PATH}/raw/en.txt\",\n",
    "    trg_path=f\"{Config.DATA_PATH}/raw/vi.txt\",\n",
    "    max_length_src=Config.MAX_LENGTH_SRC,\n",
    "    max_length_trg=Config.MAX_LENGTH_TRG\n",
    ")\n",
    "print(f\"Dataset: {df.shape}\")\n",
    "\n",
    "# Split\n",
    "train_df, val_df, test_df = preprocessor.split_data(df)\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "# Build tokenizers\n",
    "tokenizer_en, tokenizer_vi = preprocessor.build_tokenizers(train_df)\n",
    "# Save\n",
    "os.makedirs(tokenizer_path, exist_ok=True)\n",
    "save_tokenizer(tokenizer_en, f'{tokenizer_path}/tokenizer_en.pkl')\n",
    "save_tokenizer(tokenizer_vi, f'{tokenizer_path}/tokenizer_vi.pkl')\n",
    "\n",
    "# Prepare sequences\n",
    "en_train, vi_in_train, vi_out_train = preprocessor.prepare_sequences(\n",
    "    train_df, Config.MAX_LENGTH_SRC, Config.MAX_LENGTH_TRG\n",
    ")\n",
    "en_val, vi_in_val, vi_out_val = preprocessor.prepare_sequences(\n",
    "    val_df, Config.MAX_LENGTH_SRC, Config.MAX_LENGTH_TRG\n",
    ")\n",
    "\n",
    "print(f\"Training sequences: {en_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Build BiLSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T10:29:23.793210Z",
     "start_time": "2025-10-19T10:29:22.497815Z"
    },
    "execution": {
     "iopub.execute_input": "2025-10-21T04:25:49.919181Z",
     "iopub.status.busy": "2025-10-21T04:25:49.918961Z",
     "iopub.status.idle": "2025-10-21T04:25:51.480036Z",
     "shell.execute_reply": "2025-10-21T04:25:51.479333Z",
     "shell.execute_reply.started": "2025-10-21T04:25:49.919164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_builder = BiLSTMAttentionModel(\n",
    "    config=config,\n",
    "    name_logger=\"bilstm_attention\",\n",
    "    filename_logger=f\"{Config.LOG_DIR}/bilstm_attention.log\"\n",
    ")\n",
    "bilstm_model = model_builder.build(\n",
    "    vocab_size_src=Config.MAX_VOCAB_SIZE_SRC,\n",
    "    vocab_size_trg=Config.MAX_VOCAB_SIZE_TRG,\n",
    "    max_len_src=Config.MAX_LENGTH_SRC,\n",
    "    max_len_trg=Config.MAX_LENGTH_TRG\n",
    ")\n",
    "\n",
    "bilstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T04:25:51.481007Z",
     "iopub.status.busy": "2025-10-21T04:25:51.480769Z",
     "iopub.status.idle": "2025-10-21T04:25:51.484967Z",
     "shell.execute_reply": "2025-10-21T04:25:51.484335Z",
     "shell.execute_reply.started": "2025-10-21T04:25:51.480989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for layer in bilstm_model.layers[:5]:\n",
    "    print(f\"{layer.name}: dtype={layer.dtype}, compute_dtype={layer.compute_dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Train BiLSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T04:25:51.485740Z",
     "iopub.status.busy": "2025-10-21T04:25:51.485514Z",
     "iopub.status.idle": "2025-10-21T04:26:15.070054Z",
     "shell.execute_reply": "2025-10-21T04:26:15.068984Z",
     "shell.execute_reply.started": "2025-10-21T04:25:51.485724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = len(en_train) // Config.BATCH_SIZE\n",
    "Config.TOTAL_STEPS = steps_per_epoch * Config.EPOCHS\n",
    "model_name = \"bilstm\"\n",
    "\n",
    "print(f\"Total training steps: {Config.TOTAL_STEPS}\")\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Batch size (global): {Config.BATCH_SIZE}\")\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    model=bilstm_model, \n",
    "    config=config, \n",
    "    model_name=model_name,\n",
    "    logger_name=\"bilstm_attention\",\n",
    "    logger_file=f\"{Config.LOG_DIR}/bilstm_attention.log\"\n",
    ")\n",
    "\n",
    "bilstm_history = trainer.train(\n",
    "    train_data=(en_train, vi_in_train, vi_out_train),\n",
    "    val_data=(en_val, vi_in_val, vi_out_val),\n",
    "    resume=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-21T04:26:15.070526Z",
     "iopub.status.idle": "2025-10-21T04:26:15.070751Z",
     "shell.execute_reply": "2025-10-21T04:26:15.070644Z",
     "shell.execute_reply.started": "2025-10-21T04:26:15.070634Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = f\"{Config.ARTIFACT_PATH}/{model_name}\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "trainer.save_model(f\"{model_path}/bilstm_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Build LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T10:32:10.150869Z",
     "start_time": "2025-10-19T10:32:09.774285Z"
    },
    "execution": {
     "iopub.status.busy": "2025-10-21T04:26:15.071964Z",
     "iopub.status.idle": "2025-10-21T04:26:15.072261Z",
     "shell.execute_reply": "2025-10-21T04:26:15.072113Z",
     "shell.execute_reply.started": "2025-10-21T04:26:15.072099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "GPUMemoryManager.clear_session()\n",
    "\n",
    "lstm_builder = LSTMAttentionModel(\n",
    "    config=config,\n",
    "    name_logger=\"lstm_attention\",\n",
    "    filename_logger=f\"{Config.LOG_DIR}/lstm_attention.log\"\n",
    ")\n",
    "lstm_model = lstm_builder.build(\n",
    "    vocab_size_src=Config.MAX_VOCAB_SIZE_SRC,\n",
    "    vocab_size_trg=Config.MAX_VOCAB_SIZE_TRG,\n",
    "    max_len_src=Config.MAX_LENGTH_SRC,\n",
    "    max_len_trg=Config.MAX_LENGTH_TRG\n",
    ")\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Train LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-21T04:26:15.073472Z",
     "iopub.status.idle": "2025-10-21T04:26:15.073726Z",
     "shell.execute_reply": "2025-10-21T04:26:15.073631Z",
     "shell.execute_reply.started": "2025-10-21T04:26:15.073620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = \"lstm\"\n",
    "\n",
    "lstm_trainer = ModelTrainer(\n",
    "    model=lstm_model,\n",
    "    config=config,\n",
    "    model_name=model_name,\n",
    "    logger_name=\"lstm_attention\",\n",
    "    logger_file=f\"{Config.LOG_DIR}/lstm_attention.log\"\n",
    ")\n",
    "\n",
    "lstm_history = lstm_trainer.train(\n",
    "    train_data=(en_train, vi_in_train, vi_out_train),\n",
    "    val_data=(en_val, vi_in_val, vi_out_val),\n",
    "    resume=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-21T04:26:15.074964Z",
     "iopub.status.idle": "2025-10-21T04:26:15.075252Z",
     "shell.execute_reply": "2025-10-21T04:26:15.075108Z",
     "shell.execute_reply.started": "2025-10-21T04:26:15.075097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "model_path = f\"{Config.ARTIFACT_PATH}/{model_name}\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "lstm_trainer.save_model(f\"{model_path}/lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Compare Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-21T04:26:15.075843Z",
     "iopub.status.idle": "2025-10-21T04:26:15.076120Z",
     "shell.execute_reply": "2025-10-21T04:26:15.076023Z",
     "shell.execute_reply.started": "2025-10-21T04:26:15.076012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(bilstm_history.history['loss'], label='BiLSTM Train')\n",
    "axes[0].plot(bilstm_history.history['val_loss'], label='BiLSTM Val')\n",
    "axes[0].plot(lstm_history.history['loss'], label='LSTM Train', linestyle='--')\n",
    "axes[0].plot(lstm_history.history['val_loss'], label='LSTM Val', linestyle='--')\n",
    "axes[0].set_title('Model Loss Comparison')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(bilstm_history.history['accuracy'], label='BiLSTM Train')\n",
    "axes[1].plot(bilstm_history.history['val_accuracy'], label='BiLSTM Val')\n",
    "axes[1].plot(lstm_history.history['accuracy'], label='LSTM Train', linestyle='--')\n",
    "axes[1].plot(lstm_history.history['val_accuracy'], label='LSTM Val', linestyle='--')\n",
    "axes[1].set_title('Model Accuracy Comparison')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{config['assets_path']}/comparison.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-21T04:26:15.076998Z",
     "iopub.status.idle": "2025-10-21T04:26:15.077244Z",
     "shell.execute_reply": "2025-10-21T04:26:15.077117Z",
     "shell.execute_reply.started": "2025-10-21T04:26:15.077108Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"BiLSTM - Final Val Loss: {bilstm_history.history['val_loss'][-1]:.4f}\")\n",
    "print(f\"LSTM - Final Val Loss: {lstm_history.history['val_loss'][-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8534341,
     "sourceId": 13445218,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 269462127,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
